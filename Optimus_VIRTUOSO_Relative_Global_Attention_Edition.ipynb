{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Optimus_VIRTUOSO_Relative_Global_Attention_Edition.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiTIpPjArIyr"
      },
      "source": [
        "# Optimus VIRTUOSO: Relative Global Attention Edition (WIP ver. 0.5)\n",
        "\n",
        "## \"Music never allows falsehoods for even the deaf hear flat notes!\" ---OV\n",
        "\n",
        "***\n",
        "\n",
        "Powered by tegridy-tools TMIDIX Optimus Processors: https://github.com/asigalov61/tegridy-tools\n",
        "\n",
        "***\n",
        "\n",
        "Credit for GPT2-RGA code used in this colab goes out @ Sashmark97 https://github.com/Sashmark97/midigen and @ Damon Gwinn https://github.com/gwinndr/MusicTransformer-Pytorch\n",
        "\n",
        "***\n",
        "\n",
        "WARNING: This complete implementation is a functioning model of the Artificial Intelligence. Please excercise great humility, care, and respect. https://www.nscai.gov/\n",
        "\n",
        "***\n",
        "\n",
        "#### Project Los Angeles\n",
        "\n",
        "#### Tegridy Code 2021\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOd93yV0sGd2"
      },
      "source": [
        "# Setup Environment, clone needed repos, and install all required dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "lw-4aqV3sKQG"
      },
      "source": [
        "#@title nvidia-smi gpu check\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX12Yquyuihc",
        "cellView": "form"
      },
      "source": [
        "#@title Install all dependencies (run only once per session)\n",
        "\n",
        "!git clone https://github.com/asigalov61/tegridy-tools\n",
        "!pip install torch\n",
        "!pip install tqdm\n",
        "!pip install matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7n9vnKmug1J",
        "cellView": "form"
      },
      "source": [
        "#@title Import all needed modules\n",
        "\n",
        "print('Loading needed modules. Please wait...')\n",
        "import os\n",
        "from datetime import datetime\n",
        "import secrets\n",
        "import copy\n",
        "import tqdm\n",
        "from tqdm import auto\n",
        "\n",
        "if not os.path.exists('/content/Dataset'):\n",
        "    os.makedirs('/content/Dataset')\n",
        "\n",
        "print('Loading TMIDIX module...')\n",
        "os.chdir('/content/tegridy-tools/tegridy-tools')\n",
        "import TMIDIX\n",
        "\n",
        "os.chdir('/content/tegridy-tools/tegridy-tools')\n",
        "from GPT2RGA import *\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.display import display, Javascript, HTML, Audio\n",
        "\n",
        "from google.colab import output, drive\n",
        "\n",
        "os.chdir('/content/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObPxlEutsQBj"
      },
      "source": [
        "# (TRAIN FROM SCRATCH) Download and process MIDI dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "snIZ3xKPsPgB"
      },
      "source": [
        "#@title Download special Tegridy Piano MIDI dataset (Recommended)\n",
        "\n",
        "#@markdown Solo Piano\n",
        "\n",
        "#@markdown Works best stand-alone/as-is for the optimal results\n",
        "%cd /content/Dataset/\n",
        "\n",
        "!wget 'https://github.com/asigalov61/Tegridy-MIDI-Dataset/raw/master/Tegridy-Piano-CC-BY-NC-SA.zip'\n",
        "!unzip -j '/content/Dataset/Tegridy-Piano-CC-BY-NC-SA.zip'\n",
        "!rm '/content/Dataset/Tegridy-Piano-CC-BY-NC-SA.zip'\n",
        "\n",
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on7sgKEP3Yc8",
        "cellView": "form"
      },
      "source": [
        "#@title Process MIDIs to special MIDI dataset with Tegridy MIDI Processor\n",
        "#@markdown NOTES:\n",
        "\n",
        "#@markdown IMPORTANT NOTES:\n",
        "\n",
        "#@markdown 0) FOR NOW THE IMPLEMENTATION IS TUNED TO PIANO ONLY w/o MIDI CHANNELS and w/o VELOCITIES. This will be corrected in the first release version\n",
        "\n",
        "#@markdown 1) Dataset MIDI file names are used as song names. Feel free to change it to anything you like\n",
        "\n",
        "#@markdown 2) Best results are achieved with the single-track, single-channel, single-instrument MIDI 0 files with plain English names (avoid special or sys/foreign chars)\n",
        "\n",
        "#@markdown 3) MIDI Channel = -1 means all MIDI channels except the drums. MIDI Channel = 16 means all channels will be processed. Otherwise, only single indicated MIDI channel will be processed\n",
        "\n",
        "desired_dataset_name = \"Optimus-VIRTUOSO-Music-Dataset\" #@param {type:\"string\"}\n",
        "file_name_to_output_dataset_to = \"/content/Optimus-VIRTUOSO-Music-Dataset\" #@param {type:\"string\"}\n",
        "desired_MIDI_channel_to_process = 0 #@param {type:\"slider\", min:-1, max:16, step:1}\n",
        "sorted_or_random_file_loading_order = True #@param {type:\"boolean\"}\n",
        "encode_velocities = False #@param {type:\"boolean\"}\n",
        "encode_MIDI_channels = False #@param {type:\"boolean\"}\n",
        "add_transposed_dataset_by_this_many_pitches = 0 #@param {type:\"slider\", min:-12, max:12, step:1}\n",
        "add_transposed_and_flipped_dataset = False #@param {type:\"boolean\"}\n",
        "chordify_input_MIDIs = False #@param {type:\"boolean\"}\n",
        "melody_conditioned_chords = False #@param {type:\"boolean\"}\n",
        "melody_pitch_baseline = 60 #@param {type:\"slider\", min:0, max:127, step:1}\n",
        "time_denominator = 10 #@param {type:\"slider\", min:1, max:50, step:1}\n",
        "transform_to_pitch = 0 #@param {type:\"slider\", min:0, max:127, step:1}\n",
        "perfect_timings = True #@param {type:\"boolean\"}\n",
        "MuseNet_encoding = True #@param {type:\"boolean\"}\n",
        "chars_encoding_offset =  33#@param {type:\"number\"}\n",
        "\n",
        "print('TMIDI Optimus MIDI Processor')\n",
        "print('Starting up...')\n",
        "###########\n",
        "\n",
        "average_note_pitch = 0\n",
        "min_note = 127\n",
        "max_note = 0\n",
        "\n",
        "files_count = 0\n",
        "\n",
        "gfiles = 0\n",
        "\n",
        "chords_list_f = []\n",
        "melody_list_f = []\n",
        "\n",
        "chords_list = []\n",
        "chords_count = 0\n",
        "\n",
        "melody_chords = []\n",
        "melody_count = 0\n",
        "\n",
        "TXT_String = ''\n",
        "\n",
        "TXT = ''\n",
        "melody = []\n",
        "chords = []\n",
        "INTS_f = []\n",
        "###########\n",
        "\n",
        "print('Loading MIDI files...')\n",
        "print('This may take a while on a large dataset in particular.')\n",
        "\n",
        "dataset_addr = \"/content/Dataset/\"\n",
        "os.chdir(dataset_addr)\n",
        "filez = list()\n",
        "for (dirpath, dirnames, filenames) in os.walk(dataset_addr):\n",
        "    filez += [os.path.join(dirpath, file) for file in filenames]\n",
        "print('=' * 70)\n",
        "\n",
        "if filez == []:\n",
        "  print('Could not find any MIDI files. Please check Dataset dir...')\n",
        "  print('=' * 70)\n",
        "\n",
        "if sorted_or_random_file_loading_order:\n",
        "  print('Sorting files...')\n",
        "  filez.sort()\n",
        "  print('Done!')\n",
        "  print('=' * 70)\n",
        "\n",
        "# Stamping the dataset info\n",
        "print('Stamping the dataset info...')\n",
        "\n",
        "TXT_String += 'DATASET=' + str(desired_dataset_name) + chr(10)\n",
        "TXT_String += 'CREATED_ON=' + str(datetime.now()).replace(' ', '-').replace(':', '-').replace('.', '-') + chr(10)\n",
        "\n",
        "TXT_String += 'CHARS_ENCODING_OFFSET=' + str(chars_encoding_offset) + chr(10)\n",
        "TXT_String += 'TIME_DENOMINATOR=' + str(time_denominator) + chr(10)\n",
        "TXT_String += 'TRANSFORM=' + str(transform_to_pitch) + chr(10)\n",
        "TXT_String += 'PERFECT_TIMINGS=' + str(perfect_timings) + chr(10)\n",
        "TXT_String += 'MUSENET_ENCODING=' + str(MuseNet_encoding) + chr(10)\n",
        "TXT_String += 'TRANSPOSED_BY=' + str(add_transposed_dataset_by_this_many_pitches) + chr(10)\n",
        "TXT_String += 'TRANSPOSED_AND_FLIPPED=' + str(add_transposed_and_flipped_dataset) + chr(10)\n",
        "\n",
        "TXT_String += 'LEGEND=STA-DUR-PTC'\n",
        "if encode_velocities:\n",
        "  TXT_String += '-VEL'\n",
        "if encode_MIDI_channels:\n",
        "  TXT_String += '-CHA'\n",
        "TXT_String += chr(10)\n",
        "\n",
        "print('Processing MIDI files. Please wait...')\n",
        "for f in tqdm(filez):\n",
        "  try:\n",
        "    fn = os.path.basename(f)\n",
        "    fn1 = fn.split('.')[0]\n",
        "\n",
        "    files_count += 1\n",
        "    TXT, melody, chords, bass_melody, karaokez, INTS, aux1, aux2 = TMIDIX.Optimus_MIDI_TXT_Processor(f, chordify_TXT=chordify_input_MIDIs, output_MIDI_channels=encode_MIDI_channels, char_offset=chars_encoding_offset, dataset_MIDI_events_time_denominator=time_denominator, output_velocity=encode_velocities, MIDI_channel=desired_MIDI_channel_to_process, MIDI_patch=range(0, 127), melody_conditioned_encoding=melody_conditioned_chords, melody_pitch_baseline=melody_pitch_baseline, perfect_timings=perfect_timings, musenet_encoding=MuseNet_encoding, transform=transform_to_pitch)\n",
        "    TXT_String += TXT\n",
        "    melody_list_f += melody\n",
        "    chords_list_f += chords\n",
        "    INTS_f.extend(INTS)\n",
        "    gfiles += 1\n",
        "\n",
        "    if add_transposed_dataset_by_this_many_pitches != 0:\n",
        "\n",
        "      TXT, melody, chords, bass_melody, karaokez, INTS, aux1, aux2 = TMIDIX.Optimus_MIDI_TXT_Processor(f, chordify_TXT=chordify_input_MIDIs, output_MIDI_channels=encode_MIDI_channels, char_offset=chars_encoding_offset, dataset_MIDI_events_time_denominator=time_denominator, output_velocity=encode_velocities, MIDI_channel=desired_MIDI_channel_to_process, transpose_by=add_transposed_dataset_by_this_many_pitches, MIDI_patch=range(0, 127), melody_conditioned_encoding=melody_conditioned_chords, melody_pitch_baseline=melody_pitch_baseline, perfect_timings=perfect_timings, musenet_encoding=MuseNet_encoding, transform=transform_to_pitch)\n",
        "      TXT_String += TXT\n",
        "      melody_list_f += melody\n",
        "      chords_list_f += chords\n",
        "      INTS_f.extend(INTS)\n",
        "      gfiles += 1\n",
        "\n",
        "    if add_transposed_and_flipped_dataset == True:\n",
        "\n",
        "      TXT, melody, chords, bass_melody, karaokez, INTS, aux1, aux2 = TMIDIX.Optimus_MIDI_TXT_Processor(f, chordify_TXT=chordify_input_MIDIs, output_MIDI_channels=encode_MIDI_channels, char_offset=chars_encoding_offset, dataset_MIDI_events_time_denominator=time_denominator, output_velocity=encode_velocities, MIDI_channel=desired_MIDI_channel_to_process, transpose_by=-12, MIDI_patch=range(0, 127), flip=True, melody_conditioned_encoding=melody_conditioned_chords, melody_pitch_baseline=melody_pitch_baseline, perfect_timings=perfect_timings, musenet_encoding=MuseNet_encoding, transform=transform_to_pitch)\n",
        "      TXT_String += TXT\n",
        "      melody_list_f += melody\n",
        "      chords_list_f += chords\n",
        "      INTS_f.extend(INTS)\n",
        "      gfiles += 1\n",
        "\n",
        "  except KeyboardInterrupt:\n",
        "    print('Saving current progress and quitting...')\n",
        "    break  \n",
        "  \n",
        "  except:\n",
        "    print('Bad MIDI:', f)\n",
        "    continue\n",
        "\n",
        "TXT_String += 'TOTAL_SONGS_IN_DATASET=' + str(gfiles)\n",
        "\n",
        "try:\n",
        "  print('Task complete :)')\n",
        "  print('==================================================')\n",
        "  if add_transposed_dataset_by_this_many_pitches != 0:\n",
        "    print('NOTE: Transposed dataset was added per users request.')\n",
        "    print('==================================================')\n",
        "  if add_transposed_and_flipped_dataset == True:\n",
        "    print('NOTE: Flipped dataset was added per users request.')  \n",
        "    print('==================================================')\n",
        "  print('Number of processed dataset MIDI files:', files_count)\n",
        "  print('Number of MIDI chords recorded:', len(chords_list_f))\n",
        "  print('First chord event:', chords_list_f[0], 'Last chord event:', chords_list_f[-1]) \n",
        "  print('Number of recorded melody events:', len(melody_list_f))\n",
        "  print('First melody event:', melody_list_f[0], 'Last Melody event:', melody_list_f[-1])\n",
        "  print('Total number of MIDI events recorded:', len(chords_list_f) + len(melody_list_f))\n",
        "  print('==================================================')\n",
        "\n",
        "  # Writing dataset to TXT file\n",
        "  with open(file_name_to_output_dataset_to + '.txt', 'wb') as f:\n",
        "    f.write(TXT_String.encode('utf-8', 'replace'))\n",
        "    f.close\n",
        "\n",
        "  # Dataset\n",
        "  MusicDataset = [chords_list_f, melody_list_f, INTS_f]\n",
        "\n",
        "  # Writing dataset to pickle file\n",
        "  TMIDIX.Tegridy_Any_Pickle_File_Writer(MusicDataset, file_name_to_output_dataset_to)\n",
        "\n",
        "except:\n",
        "  print('=' * 70)\n",
        "  print('IO Error!')\n",
        "  print('Please check that Dataset dir is not empty/check other IO code.')\n",
        "  print('=' * 70)\n",
        "  print('Shutting down...')\n",
        "  print('=' * 70)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT0TyqUnpxu_",
        "cellView": "form"
      },
      "source": [
        "#@title Load processed INTs datasets\n",
        "number_of_batches = 2 #@param {type:\"slider\", min:2, max:32, step:2}\n",
        "\n",
        "print('=' * 50)\n",
        "print('Prepping INTs datasets...')\n",
        "train_data = []\n",
        "for i in INTS_f:\n",
        "  if i[0] < TOKEN_END and i[1] < TOKEN_END:\n",
        "      # train_data.extend(i)\n",
        "      train_data.extend([i[0], i[1], i[3]])\n",
        "      train_data.extend([10])\n",
        "val_dataset = train_data[:int(len(train_data) * 0.3)]\n",
        "test_dataset = train_data[:int(len(train_data) * 0.3)]\n",
        "\n",
        "train_list = train_data\n",
        "val_list = val_dataset\n",
        "test_list = []\n",
        "print('=' * 50)\n",
        "\n",
        "print('Processing INTs datasets...')\n",
        "train_dataset = EPianoDataset(train_list, max_seq, random_seq)\n",
        "val_dataset = EPianoDataset(val_list, max_seq)\n",
        "test_dataset = EPianoDataset(test_list, max_seq)\n",
        "print('=' * 50)\n",
        "\n",
        "print('Loading INTs datasets...')\n",
        "batch_size = number_of_batches\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=n_workers, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=n_workers)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=n_workers)\n",
        "print('=' * 50)\n",
        "\n",
        "print('Total INTs in the dataset', len(train_data))\n",
        "print('Total unique INTs in the dataset', len(set(train_data)))\n",
        "print('Max INT in the dataset', max(train_data))\n",
        "print('Min INT in the dataset', min(train_data))\n",
        "print('=' * 50)\n",
        "\n",
        "print('Checking datasets shapes...')\n",
        "print('=' * 50)\n",
        "\n",
        "print('Train loader')\n",
        "for x, tgt in train_loader:\n",
        "    print(f'X shape: {x.shape}')\n",
        "    print(f'Target shape: {tgt.shape}')\n",
        "    break\n",
        "print('=' * 50)\n",
        "\n",
        "print('Validation loader')\n",
        "for x, tgt in val_loader:\n",
        "    print(f'X shape: {x.shape}')\n",
        "    print(f'Target shape: {tgt.shape}')\n",
        "    break\n",
        "print('=' * 50)\n",
        "\n",
        "print('Test loader')\n",
        "for x, tgt in test_loader:\n",
        "    print(f'X shape: {x.shape}')\n",
        "    print(f'Target shape: {tgt.shape}')\n",
        "    break\n",
        "print('=' * 50)\n",
        "\n",
        "print('Done! Enjoy! :)')\n",
        "print('=' * 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9CBW8xYupH8"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2moo7uUmpxvC",
        "cellView": "form"
      },
      "source": [
        "#@title Train\n",
        "config = GPTConfig(VOCAB_SIZE, \n",
        "                   max_seq,\n",
        "                   dim_feedforward=dim_feedforward,\n",
        "                   n_layer=6, \n",
        "                   n_head=8, \n",
        "                   n_embd=512,\n",
        "                   enable_rpr=True,\n",
        "                   er_len=max_seq)\n",
        "model = GPT(config).to(get_device())\n",
        "\n",
        "#=====\n",
        "\n",
        "init_step = 0\n",
        "lr = LR_DEFAULT_START\n",
        "lr_stepper = LrStepTracker(d_model, SCHEDULER_WARMUP_STEPS, init_step)\n",
        "eval_loss_func = nn.CrossEntropyLoss(ignore_index=TOKEN_PAD)\n",
        "train_loss_func = eval_loss_func\n",
        "\n",
        "opt = Adam(model.parameters(), lr=lr, betas=(ADAM_BETA_1, ADAM_BETA_2), eps=ADAM_EPSILON)\n",
        "lr_scheduler = LambdaLR(opt, lr_stepper.step)\n",
        "\n",
        "\n",
        "#===\n",
        "\n",
        "best_eval_acc        = 0.0\n",
        "best_eval_acc_epoch  = -1\n",
        "best_eval_loss       = float(\"inf\")\n",
        "best_eval_loss_epoch = -1\n",
        "best_acc_file = '/content/gpt2_rpr_acc.pth'\n",
        "best_loss_file = '/content/gpt2_rpr_loss.pth'\n",
        "loss_train, loss_val, acc_val = [], [], []\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "    new_best = False\n",
        "    \n",
        "    loss = train(epoch+1, model, train_loader, train_loss_func, opt, lr_scheduler, num_iters=-1)\n",
        "    loss_train.append(loss)\n",
        "    \n",
        "    eval_loss, eval_acc = eval_model(model, val_loader, eval_loss_func, num_iters=-1)\n",
        "    loss_val.append(eval_loss)\n",
        "    acc_val.append(eval_acc)\n",
        "    \n",
        "    if(eval_acc > best_eval_acc):\n",
        "        best_eval_acc = eval_acc\n",
        "        best_eval_acc_epoch  = epoch+1\n",
        "        torch.save(model.state_dict(), best_acc_file)\n",
        "        new_best = True\n",
        "\n",
        "    if(eval_loss < best_eval_loss):\n",
        "        best_eval_loss       = eval_loss\n",
        "        best_eval_loss_epoch = epoch+1\n",
        "        torch.save(model.state_dict(), best_loss_file)\n",
        "        new_best = True\n",
        "    \n",
        "    if(new_best):\n",
        "        print(\"Best eval acc epoch:\", best_eval_acc_epoch)\n",
        "        print(\"Best eval acc:\", best_eval_acc)\n",
        "        print(\"\")\n",
        "        print(\"Best eval loss epoch:\", best_eval_loss_epoch)\n",
        "        print(\"Best eval loss:\", best_eval_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNqmcFdRyC2M",
        "cellView": "form"
      },
      "source": [
        "#@title Plot resulting training loss graph\n",
        "\n",
        "tr_loss_list = [item for sublist in loss_train for item in sublist]\n",
        "plt.plot([i for i in range(len(tr_loss_list))] ,tr_loss_list, 'b')\n",
        "plt.savefig('/content/training-loss.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdKFoeke9L7H"
      },
      "source": [
        "# Save or load/reload the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqyDatHC9X1z",
        "cellView": "form"
      },
      "source": [
        "#@title Save the model\n",
        "\n",
        "print('Saving the model...')\n",
        "full_path_to_model_checkpoint = \"/content/Optimus-VIRTUOSO-Trained-Model.pth\" #@param {type:\"string\"}\n",
        "torch.save(model.state_dict(), full_path_to_model_checkpoint)\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaNkGcFo9UP_",
        "cellView": "form"
      },
      "source": [
        "#@title Load/re-load the model\n",
        "full_path_to_model_checkpoint = \"/content/Optimus-VIRTUOSO-Trained-Model.pth\" #@param {type:\"string\"}\n",
        "\n",
        "print('Loading the model...')\n",
        "config = GPTConfig(VOCAB_SIZE, \n",
        "                   max_seq,\n",
        "                   dim_feedforward=dim_feedforward,\n",
        "                   n_layer=6, \n",
        "                   n_head=8, \n",
        "                   n_embd=512,\n",
        "                   enable_rpr=True,\n",
        "                   er_len=max_seq)\n",
        "\n",
        "model = GPT(config).to(get_device())\n",
        "\n",
        "model.load_state_dict(torch.load(full_path_to_model_checkpoint))\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX1_5y5Fu8AH"
      },
      "source": [
        "# Generate music"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "M_K93hWWv2Yx"
      },
      "source": [
        "#@title Generate and download a MIDI file\n",
        "\n",
        "#@markdown Please note that only the first generated composition is being converted to MIDI by default. Please check the output TXT file for extra generated compositions.\n",
        "number_of_ticks_per_quarter = 500 #@param {type:\"slider\", min:50, max:1000, step:50}\n",
        "dataset_time_denominator = 1 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "melody_conditioned_encoding = False\n",
        "encoding_has_MIDI_channels = False #@param {type:\"boolean\"}\n",
        "encoding_has_velocities = False #@param {type:\"boolean\"}\n",
        "simulate_velocity = True #@param {type:\"boolean\"}\n",
        "save_only_first_composition = True #@param {type:\"boolean\"}\n",
        "chars_encoding_offset_used_for_dataset = 33 #@param {type:\"number\"}\n",
        "\n",
        "fname = '/content/Optimus-VIRTUOSO-Composition'\n",
        "\n",
        "print('Converting Song to MIDI...')\n",
        "\n",
        "output_signature = 'Optimus VIRTUOSO'\n",
        "\n",
        "model.eval()\n",
        "idx = secrets.randbelow(len(train_data))\n",
        "rand_seq = model.generate(torch.Tensor(train_data[idx:idx+120]), target_seq_length=2048)\n",
        "out = rand_seq[0].cpu().numpy().tolist()\n",
        "\n",
        "song = []\n",
        "sng = []\n",
        "for o in out:\n",
        "#for o in train_data:\n",
        "  if o != 10:\n",
        "    sng.append(o)\n",
        "  else:\n",
        "    if len(sng) == 3:\n",
        "      song.append(sng)\n",
        "    sng = []\n",
        "\n",
        "char_offset = 33\n",
        "song_f = []\n",
        "time = 0\n",
        "for s in song:\n",
        "  \n",
        "  song_f.append(['note', (abs(time)) * 10, (s[1]-char_offset) * 10, 0, s[2]-char_offset, s[2]-char_offset])\n",
        "  time += s[0] - char_offset\n",
        "\n",
        "detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
        "                                                      output_signature = output_signature,  \n",
        "                                                      output_file_name = fname, \n",
        "                                                      track_name=song_name, \n",
        "                                                      number_of_ticks_per_quarter=number_of_ticks_per_quarter)\n",
        "\n",
        "print('Done!')\n",
        "\n",
        "print('Downloading your composition now...')\n",
        "from google.colab import files\n",
        "files.download(fname + '.mid')\n",
        "\n",
        "print('Detailed MIDI stats:')\n",
        "detailed_stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAJvQMaKv-n-"
      },
      "source": [
        "# Plot and listen to the last output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "bEfNym54v5dr"
      },
      "source": [
        "#@title Install prerequisites\n",
        "!apt install fluidsynth #Pip does not work for some reason. Only apt works\n",
        "!pip install midi2audio\n",
        "!pip install pretty_midi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "-Nq86-0Tv7tI"
      },
      "source": [
        "#@title Plot and listen to the last generated composition\n",
        "#@markdown NOTE: May be very slow with the long compositions\n",
        "from midi2audio import FluidSynth\n",
        "from IPython.display import display, Javascript, HTML, Audio\n",
        "import pretty_midi\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "import numpy as np\n",
        "\n",
        "print('Synthesizing the last output MIDI... ')\n",
        "# fname = '/content/Endless-Piano-Music-Composition'\n",
        "\n",
        "fn = os.path.basename(fname + '.mid')\n",
        "fn1 = fn.split('.')[0]\n",
        "\n",
        "print('Plotting the composition. Please wait...')\n",
        "\n",
        "pm = pretty_midi.PrettyMIDI(fname + '.mid')\n",
        "\n",
        "# Retrieve piano roll of the MIDI file\n",
        "piano_roll = pm.get_piano_roll()\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "librosa.display.specshow(piano_roll, x_axis='time', y_axis='cqt_note', fmin=1, hop_length=160, sr=16000, cmap=plt.cm.hot)\n",
        "plt.title(fn1)\n",
        "\n",
        "FluidSynth(\"/usr/share/sounds/sf2/FluidR3_GM.sf2\", 16000).midi_to_audio(str(fname + '.mid'), str(fname + '.wav'))\n",
        "Audio(str(fname + '.wav'), rate=16000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzCMd94Tu_gz"
      },
      "source": [
        "# Congrats! You did it! :)"
      ]
    }
  ]
}