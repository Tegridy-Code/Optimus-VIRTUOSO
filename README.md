# Optimus-VIRTUOSO

## GPT2/GPT3-based Multi-Instrumental MIDI Music AI implementation

***

### Now featuring TMIDIX improved reproduction of the MuseNet multi-instrumental TXT encoding 

What are you waiting for?!? Try it out!!! :)

[![Open In Colab][colab-badge]][colab-notebook]

[colab-notebook]: <https://colab.research.google.com/github/asigalov61/Optimus-VIRTUOSO/blob/main/Optimus_VIRTUOSO.ipynb>
[colab-badge]: <https://colab.research.google.com/assets/colab-badge.svg>

This is an auto-regressive implementation (char-based approach) which has its benefits but also drawbacks.
However, this is the most interesting and fastest implementation because it allows to do many different things.

For non-auto-regressive token-based approach see Optimus VIRTUOSO RGA Edition below.

***

### ORIGINAL COMPOSITION: Optimus-VIRTUOSO Compound Music Composer with custom MIDI option

This is basically an improved reproduction of OpenAI's MuseNet. With large enough dataset, you should get comparable(or better) results.

And no, you do not really need Sparse Attention/Transformers here unless you want to train on gigabytes of data

[![Open In Colab][colab-badge1]][colab-notebook1]

[colab-notebook1]: <https://colab.research.google.com/github/asigalov61/Optimus-VIRTUOSO/blob/main/Optimus_VIRTUOSO_Composer.ipynb>
[colab-badge1]: <https://colab.research.google.com/assets/colab-badge.svg>

***

### BEST OF BOTH WORLDS: Optimus VIRTUOSO: Relative Global Attention Edition

GPT3 + RGA(RPR) = AWESOME

If OpenAi's MuseNet and Google Piano Transformer could have a baby, that would be it :) 

[![Open In Colab][colab-badge2]][colab-notebook2]

[colab-notebook2]: <https://colab.research.google.com/github/asigalov61/Optimus-VIRTUOSO/blob/main/Optimus_VIRTUOSO_Relative_Global_Attention_Edition.ipynb>
[colab-badge2]: <https://colab.research.google.com/assets/colab-badge.svg>

***

### SoundCloud:

https://soundcloud.com/aleksandr-sigalov-61/sets/exclusive-preview-optimus-virtuoso

***

### Some specs/stats:

1) Multi-instrumental MIDI implementation

2) Human-readable TXT Encoding with only 3 (three) to 5 (five) UTF-8 chars per any MIDI note (5 x 4bytes/char == 20 bytes max)

3) MuseNet-like MIDI events representation

4) Composition-level MIDI events representation

6) Single-epoch/one-shot training/learning

7) GPT3 tweaks/improvements

8) Relative Global Attention (RPR)

9) Much much more...

***

### FAQ:

Q) What Optimus-VIRTUOSO can do for me?

A) Optimus-VIRTUOSO can virtuosly play you any MIDI music you will train it upon.

***

Q) What Optimus-VIRTUOSO can't do for me?

A) Optimus-VIRTUOSO can't compose fully original music for you because it is a regular Music AI (not AGI) implementation.

***

Q) Is there any way to compose original music with Optimus-VIRTUOSO?

A) Yes! Try Optimus-VIRTUOSO Composer! It can compose compound music for you, similar to how MuseNet does it. It is not going to be fully original but it is not going to be a complete plagiarism either :)

***

Q) What are the possible useful practical applications for this technology?

A) Great question! Here are the major ones in order of importance and ability:

1) Music Performance: Think talented AI Music Protege or an AI Music partner for a musician or a composer
2) Music Composition: Think of it as an AI Music colloborator for musicians and composers
3) Music Classification: This is most profitable and useful application at the moment, but this would be a rather simple and crude use of such great tech
4) Music Exploration: This is also very interesting application, especially if it would be somehow tied with the #1 and #2 above
5) Many more other incredible uses, so definitely give the Optimus VIRTUOSO a try :)

***

#### Project Los Angeles

#### Tegridy Code 2021
